{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn-scratch-training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1A8FjI4E3IU1QGePzaYLp2YmRQNmNsOuX",
      "authorship_tag": "ABX9TyO03l8wr36jJTO3WWEFtglt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Suraj-Kaple/Simple-CNN-classifier-pytorch/blob/main/cnn_scratch_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvRMoNcSqVZW",
        "outputId": "63b59eba-40e7-448a-b32c-fb0b16e74fff"
      },
      "source": [
        "# mount google drive to access folders and files present on drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqoUctaeaO_g",
        "outputId": "dd7cd9c8-a115-4b63-c7bc-7c18c0cad66e"
      },
      "source": [
        "%cd /content/drive/MyDrive/Colab Notebooks/1_Intel Image Classification"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/1_Intel Image Classification\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CczMbU2nfNAt"
      },
      "source": [
        "# import required libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import glob\n",
        "import torch.nn as nn\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.autograd import Variable\n",
        "import torchvision\n",
        "import pathlib"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VnJamoDgolg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d088978b-4c89-4c4d-b1f0-4292fdb11237"
      },
      "source": [
        "# check for device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvFJchxDgxqB"
      },
      "source": [
        "# Transforms\n",
        "transformer = transforms.Compose([\n",
        "    transforms.ToTensor(),  # convert a numpy.ndarray (H x W x C) in the range [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0]\n",
        "    transforms.Resize((150,150)), # resize the image to size (150,150) ~ (h,w) \n",
        "    transforms.RandomHorizontalFlip(),  # flip the image horizontally with probability 0.5\n",
        "    transforms.Normalize([0.5,0.5,0.5],  # [0.0,1.0] to [-1.0,-1.0], formula (input-mean)/std \n",
        "                         [0.5,0.5,0.5])\n",
        "])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whdtZGQBjN4K"
      },
      "source": [
        "# Dataloader (reading data and feeding data to the model for training in batches)\n",
        "# Batches are required to avoid memory overload\n",
        "\n",
        "train_path = '/content/drive/MyDrive/Colab Notebooks/1_Intel Image Classification/scene_detection/seg_train/seg_train'\n",
        "test_path = '/content/drive/MyDrive/Colab Notebooks/1_Intel Image Classification/scene_detection/seg_test/seg_test'\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    torchvision.datasets.ImageFolder(train_path,transform=transformer),\n",
        "    batch_size=256, shuffle=True\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    torchvision.datasets.ImageFolder(test_path,transform=transformer),\n",
        "    batch_size=256, shuffle=True\n",
        ")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhzKOH0FlkKr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2a844f8-3478-4102-e34f-e1ff57905adf"
      },
      "source": [
        "# Categories (output classes)\n",
        "root = pathlib.Path(train_path)\n",
        "classes = sorted([j.name for j in root.iterdir()])  # iterate over the files in this directory and create a classes list \n",
        "print(classes)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGoFHlh-nowa"
      },
      "source": [
        "# CNN class\n",
        "class ConvNet(nn.Module):\n",
        "  def __init__(self,num_classes=6):\n",
        "    super(ConvNet,self).__init__()    # initialize the parent class to use its properties\n",
        "\n",
        "    # Output size afetr convolution filter\n",
        "    # ((w-f+2P)/s) + 1\n",
        "\n",
        "    # Input shape = (256,3,150,150)\n",
        "\n",
        "    self.conv1 = nn.Conv2d(in_channels=3,out_channels=12,kernel_size=3,stride=1,padding=1)\n",
        "    # shape = (256,12,150,150)\n",
        "    self.bn1 = nn.BatchNorm2d(num_features=12)\n",
        "    # shape = (256,12,150,150)\n",
        "    self.relu1 = nn.ReLU()\n",
        "    # shape = (256,12,150,150)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2)\n",
        "    # shape = (256,12,75,75)\n",
        "\n",
        "    self.conv2 = nn.Conv2d(in_channels=12,out_channels=20,kernel_size=3,stride=1,padding=1)\n",
        "    # shape = (256,20,75,75)\n",
        "    self.relu2 = nn.ReLU()\n",
        "    # shape = (256,20,75,75)\n",
        "\n",
        "    self.conv3 = nn.Conv2d(in_channels=20,out_channels=32,kernel_size=3,stride=1,padding=1)\n",
        "    # shape = (256,32,75,75)\n",
        "    self.bn3 = nn.BatchNorm2d(num_features=32)\n",
        "    # shape = (256,32,75,75)\n",
        "    self.relu3 = nn.ReLU()\n",
        "    # shape = (256,32,75,75)\n",
        "\n",
        "    self.fc = nn.Linear(in_features=32*75*75,out_features=num_classes)\n",
        "\n",
        "  # Feed forward function\n",
        "  def forward(self,input):\n",
        "    output = self.conv1(input)\n",
        "    output = self.bn1(output)\n",
        "    output = self.relu1(output)\n",
        "\n",
        "    output = self.pool(output)\n",
        "\n",
        "    output = self.conv2(output)\n",
        "    output = self.relu2(output)\n",
        "\n",
        "    output = self.conv3(output)\n",
        "    output = self.bn3(output)\n",
        "    output = self.relu3(output)\n",
        "\n",
        "    # Above output will be in matrix form with shape (256,32,75,75)\n",
        "    output = output.view(-1,32*75*75)\n",
        "\n",
        "    output = self.fc(output)\n",
        "\n",
        "    return output"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3Jdq0NMsVsw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b81aced5-621b-472e-d067-d378e2e99a65"
      },
      "source": [
        "model = ConvNet(num_classes=len(classes)).to(device)  # creating an instance of out CNN\n",
        "print(model)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ConvNet(\n",
            "  (conv1): Conv2d(3, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu1): ReLU()\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(12, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (relu2): ReLU()\n",
            "  (conv3): Conv2d(20, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu3): ReLU()\n",
            "  (fc): Linear(in_features=180000, out_features=6, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbmQG1fhsbzw"
      },
      "source": [
        "# Optimizer and loss function\n",
        "optimizer = Adam(model.parameters(),lr=0.001,weight_decay=0.0001)\n",
        "loss_function = nn.CrossEntropyLoss()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4E2hCdUtbio"
      },
      "source": [
        "num_epochs = 10"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7ETNh_atdL1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c4ce847-7a2f-422f-f2a2-1034be346286"
      },
      "source": [
        "# calculating the size of the training and testing images\n",
        "train_count = len(glob.glob(train_path+'/**/*.jpg'))\n",
        "test_count = len(glob.glob(test_path+'/**/*.jpg'))\n",
        "print(train_count,test_count)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14034 3000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0-PH2nut5ur",
        "outputId": "f87c6648-130d-4a13-b184-0f6d81398bcf"
      },
      "source": [
        "#Model training and saving best model\n",
        "\n",
        "best_accuracy=0.0\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "  #Evaluation and training on training dataset\n",
        "  model.train()   # set model in training mode\n",
        "  train_accuracy=0.0\n",
        "  train_loss=0.0\n",
        "  \n",
        "  for i, (images,labels) in enumerate(train_loader):\n",
        "    if torch.cuda.is_available():\n",
        "        images=Variable(images.cuda())\n",
        "        labels=Variable(labels.cuda())\n",
        "        \n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    outputs=model(images)\n",
        "    loss=loss_function(outputs,labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    train_loss+= loss.cpu().data*images.size(0)\n",
        "    _,prediction=torch.max(outputs.data,1)\n",
        "    \n",
        "    train_accuracy+=int(torch.sum(prediction==labels.data))\n",
        "    \n",
        "  train_accuracy=train_accuracy/train_count\n",
        "  train_loss=train_loss/train_count\n",
        "  \n",
        "  # Evaluation on testing dataset\n",
        "  model.eval()    # set model in testing mode\n",
        "  test_accuracy=0.0\n",
        "  for i, (images,labels) in enumerate(test_loader):\n",
        "    if torch.cuda.is_available():\n",
        "        images=Variable(images.cuda())\n",
        "        labels=Variable(labels.cuda())\n",
        "        \n",
        "    outputs=model(images)\n",
        "    _,prediction=torch.max(outputs.data,1)\n",
        "    test_accuracy+=int(torch.sum(prediction==labels.data))\n",
        "  \n",
        "  test_accuracy=test_accuracy/test_count\n",
        "  \n",
        "  print('Epoch: '+str(epoch)+' Train Loss: '+str(train_loss)+' Train Accuracy: '+str(train_accuracy)+' Test Accuracy: '+str(test_accuracy))\n",
        "  \n",
        "  #Save the best model\n",
        "  if test_accuracy>best_accuracy:\n",
        "    torch.save(model.state_dict(),'best_checkpoint.model')\n",
        "    best_accuracy=test_accuracy"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 Train Loss: tensor(9.7150) Train Accuracy: 0.5360552942853071 Test Accuracy: 0.5776666666666667\n",
            "Epoch: 1 Train Loss: tensor(1.3424) Train Accuracy: 0.7092774690038478 Test Accuracy: 0.593\n",
            "Epoch: 2 Train Loss: tensor(0.9612) Train Accuracy: 0.7731224169873165 Test Accuracy: 0.7196666666666667\n",
            "Epoch: 3 Train Loss: tensor(0.6583) Train Accuracy: 0.8339033775117571 Test Accuracy: 0.7143333333333334\n",
            "Epoch: 4 Train Loss: tensor(0.6189) Train Accuracy: 0.8452330055579308 Test Accuracy: 0.6423333333333333\n",
            "Epoch: 5 Train Loss: tensor(0.4705) Train Accuracy: 0.8746615362690608 Test Accuracy: 0.6716666666666666\n",
            "Epoch: 6 Train Loss: tensor(0.3632) Train Accuracy: 0.904232578024797 Test Accuracy: 0.7193333333333334\n",
            "Epoch: 7 Train Loss: tensor(0.2728) Train Accuracy: 0.9249679350149637 Test Accuracy: 0.719\n",
            "Epoch: 8 Train Loss: tensor(0.1739) Train Accuracy: 0.9494085791648853 Test Accuracy: 0.7403333333333333\n",
            "Epoch: 9 Train Loss: tensor(0.1191) Train Accuracy: 0.9665811600399031 Test Accuracy: 0.7486666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}